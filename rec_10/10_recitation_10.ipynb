{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div dir=rtl> תרגול עשירי - The return of Feature Selection </div>\n",
    "\n",
    "<div dir=rtl>\n",
    "     בתרגול זה נכיר שיטות נוספות לבחירת פיצ'רים בהינתן דאטא סט ומודל. נשתמש במודל לבחירת הפיצ'רים.\n",
    "    <br />\n",
    "    בתרגול הקודם ראינו איך ניתן לבחור פיצ'רים על ידי השוואה בינם לבין עצמם או בינם ובין הלייבל (שיטות פילטר). כעת נדון על שיטות לבחירת פיצ'רים באמצעות מודל כלשהו. נאמן את המודל, נבדוק מדד טיב כלשהו לגבי המודל (אותו נרצה לאפטם) ונסיק מסקנות לגבי הפיצ'רים.\n",
    "    <br />\n",
    "</div>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/0/04/Feature_selection_Wrapper_Method.png)\n",
    "\n",
    "<div dir=rtl>\n",
    "     בתרגול נדון בשלוש שיטות:</div>\n",
    "\n",
    "- Forward selection\n",
    "- Backward elimination\n",
    "- Recursive Feature Elimination\n",
    "\n",
    "## <div dir=rtl> שאלה  1 </div>\n",
    "<div dir=rtl>\n",
    "     בשנת 1988 פרסמו במשותף מספר מכוני מחקר באירופה מידע על אודות 303 חולי לב. המידע כלל נתונים שהוזנו בעת הגעה של המטופל לבית החולים לבדיקה.\n",
    "    <br />\n",
    "    המידע קיים בקובץ 9.heart.csv\n",
    "</div>\n",
    "\n",
    "<div dir=rtl>\n",
    "     א. טענו את הקובץ לאובייקט המתים למידע טבלאי.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m10_recitation_10.html\u001b[m\u001b[m*  \u001b[31m10_recitation_10.ipynb\u001b[m\u001b[m* \u001b[31m9.heart.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "164   38    1   2       138   175    0        1      173      0      0.0   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "203   68    1   2       180   274    1        0      150      1      1.6   \n",
       "59    57    0   0       128   303    0        0      159      0      0.0   \n",
       "86    68    1   2       118   277    0        1      151      0      1.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "164      2   4     2       1  \n",
       "63       1   0     1       1  \n",
       "203      1   0     3       0  \n",
       "59       2   1     2       1  \n",
       "86       2   1     3       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('9.heart.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         303.0\n",
       "sex         303.0\n",
       "cp          303.0\n",
       "trestbps    303.0\n",
       "chol        303.0\n",
       "fbs         303.0\n",
       "restecg     303.0\n",
       "thalach     303.0\n",
       "exang       303.0\n",
       "oldpeak     303.0\n",
       "slope       303.0\n",
       "ca          303.0\n",
       "thal        303.0\n",
       "target      303.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc['count', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     ב. חלקו את הדאטא לשלוש קבוצות: אחת המכילה 80 אחוז מהנתונים ועוד שתיים בגודל שווה.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "     נשים לב שבניגוד לתרגולים קודמים, כעת מבקשים מאיתנו שלוש קבוצת. אחת גדולה ועוד שתיים קטנות. אנחנו נפרש את ההנחיה לפי המנהג התקין באימון מודלים של למידת מכונה - על קבוצה אחת נתאמן, בעזרת הקבוצה השנייה נשנה את המטה-פרמטרים של המודל ונאמן שוב כדי לשפר את התוצאות ועל קבוצה שלישית ניבחן.\n",
    "    מנהג נכון הוא לדאוג להתפלגות זהה של המחלקות בכל אחת מהקבוצות. ראינו בעבר איך ניתן לבצע זאת לחלוקה לשתי קבוצות על ידי הפונקציה train_test_split והארגומנט stratify. כעת נחלק את הקבוצה הקטנה שוב.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df shape (242, 14) \n",
      "test+validation df shape (61, 14) \n",
      "\n",
      "\n",
      "validation df shape (30, 14) \n",
      "test df shape (31, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test_val = train_test_split(\n",
    "    df,\n",
    "    stratify=df['target'],\n",
    "    train_size = 0.8,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print('train df shape', df_train.shape, '\\ntest+validation df shape', df_test_val.shape, '\\n\\n')\n",
    "\n",
    "df_val, df_test = train_test_split(\n",
    "    df_test_val,\n",
    "    stratify=df_test_val['target'],\n",
    "    test_size = 0.5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print('validation df shape', df_val.shape, '\\ntest df shape', df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     נשים לב שהקבוצות מדויקות עד כדי עיגול למספרים שלמים.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "     ג. מיצאו פיצ'ר אחד כלשהו המסווג את הדאטא בצורה אופטימלית עבור מודל רגרסיה לוגיסטית.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: age, accuracy: 0.6\n",
      "feature: sex, accuracy: 0.7\n",
      "feature: cp, accuracy: 0.7666666666666667\n",
      "feature: trestbps, accuracy: 0.5666666666666667\n",
      "feature: chol, accuracy: 0.5333333333333333\n",
      "feature: fbs, accuracy: 0.5333333333333333\n",
      "feature: restecg, accuracy: 0.4666666666666667\n",
      "feature: thalach, accuracy: 0.7333333333333333\n",
      "feature: exang, accuracy: 0.7\n",
      "feature: oldpeak, accuracy: 0.7\n",
      "feature: slope, accuracy: 0.7\n",
      "feature: ca, accuracy: 0.7666666666666667\n",
      "feature: thal, accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "for feature in df_train.drop('target', axis='columns'):\n",
    "    lr = LogisticRegression(max_iter = 1e3)\n",
    "    \n",
    "    lr.fit(df_train[feature].values.reshape(-1,1), df_train['target'])\n",
    "    predictions = lr.predict(df_val[feature].values.reshape(-1,1))\n",
    "    \n",
    "    print(f'feature: {feature}, accuracy: {accuracy_score(df_val[\"target\"], predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     למעלה - עברנו על כל עמודה של הדאטא ואימנו מודל מסוג רגרסיה לוגיסטית. מהנתונים עולה מהו הפיצ'ר המבוקש:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['cp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     ד. מצאו שלושה פיצ'רים נוספים עבורם הסיווג אופטימלי. ביחנו את עצמכם על קבוצת הוולידציה ועל קבוצת המבחן.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "     מההנחיה עולה כי כעת נדרש להגיע לקבוצה בעלת ארבעה פיצ'רים כאשר אחד מהם הוא הפיצ'ר אותו בחרנו בסעיף הקודם. לשיטה זו קוראים Forward Selection (או במקומות מסוימים Sequential Forward Selection).\n",
    "    <br />\n",
    "    נבצע זאת על ידי מעבר על כל הפיצ'רים ובדיקת הפיצ'ר שיחד עם זה שבחרנו למעלה נותן סיווג אופטימלי. לאחר מכן נעבור שוב על כל הפיצ'רים שנבחרו ונבחר את הפיצ'ר האופטימלי עבור השלשה וכן הלאה.\n",
    "    <br />\n",
    "    מה החיסרון של השיטה?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== iteration num 0 ===\n",
      " fetures selected ['cp', 'chol']\n",
      "== iteration num 1 ===\n",
      " fetures selected ['cp', 'chol', 'oldpeak']\n",
      "== iteration num 2 ===\n",
      " fetures selected ['cp', 'chol', 'oldpeak', 'age']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cp', 'chol', 'oldpeak', 'age']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = ['cp']\n",
    "\n",
    "for iteration in range(3):\n",
    "\n",
    "    accuracies = []\n",
    "    \n",
    "    for feature in df_train.drop(selected_features + ['target'], axis='columns'):\n",
    "        \n",
    "        lr = LogisticRegression(max_iter = 1e3)\n",
    "        \n",
    "        lr.fit(df_train[selected_features + [feature]], df_train['target'])\n",
    "        predictions = lr.predict(df_val[selected_features + [feature]])\n",
    "        \n",
    "        accuracies.append((feature,accuracy_score(df_val[\"target\"], predictions)))\n",
    "        \n",
    "    accuracies_df = pd.DataFrame(accuracies, columns=['feature', 'accuracy'])  \n",
    "    selected_features.append(\n",
    "        accuracies_df.iloc[accuracies_df['accuracy'].idxmax(),0]\n",
    "    )\n",
    "    print(f\"== iteration num {iteration} ===\\n fetures selected {selected_features}\")\n",
    "\n",
    "selected_features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     מצאנו סט של ארבעה פיצ'רים כמבוקש. ניבחן על קבוצת הוולידציה ועל קבוצת המבחן:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 1e3)\n",
    "lr.fit(df_train[selected_features], df_train['target'])\n",
    "\n",
    "predictions = lr.predict(df_val[selected_features])\n",
    "accuracy_score(df_val[\"target\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741935483870968"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr.predict(df_test[selected_features])\n",
    "accuracy_score(df_test[\"target\"], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     ה. מה איכות הסיווג של מסווג לינארי עם כלל הפיצ'רים? מצאו אילו פיצ'רים כדאי להוריד כך שתישארו עם ארבעה פיצ'רים. ביחנו את עצמכם הן על קבוצת הוולידציה והן על קבוצת המבחן.\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "     כעת נמצא את איכות הסיווג תוך שימוש בכלל הפיצ'רים. עבור סעיף זה בחרתי להשתמש במימוש של statsmodels ומיד נבין למה.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347078\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "lr = sm.Logit(df_train['target'], sm.add_constant(df_train.drop('target', axis='columns')))\n",
    "\n",
    "results = lr.fit()\n",
    "\n",
    "predictions = results.predict(sm.add_constant(df_val.drop('target', axis='columns')))>=0.5\n",
    "accuracy_score(df_val[\"target\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td>   242</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   228</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    13</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 07 May 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.4963</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:05:28</td>     <th>  Log-Likelihood:    </th> <td> -83.993</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -166.74</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.518e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    4.5270</td> <td>    3.012</td> <td>    1.503</td> <td> 0.133</td> <td>   -1.377</td> <td>   10.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>      <td>   -0.0069</td> <td>    0.027</td> <td>   -0.255</td> <td> 0.799</td> <td>   -0.060</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>      <td>   -1.4691</td> <td>    0.523</td> <td>   -2.807</td> <td> 0.005</td> <td>   -2.495</td> <td>   -0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp</th>       <td>    0.9343</td> <td>    0.213</td> <td>    4.379</td> <td> 0.000</td> <td>    0.516</td> <td>    1.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trestbps</th> <td>   -0.0217</td> <td>    0.012</td> <td>   -1.880</td> <td> 0.060</td> <td>   -0.044</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>     <td>   -0.0032</td> <td>    0.004</td> <td>   -0.742</td> <td> 0.458</td> <td>   -0.012</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>      <td>    0.2254</td> <td>    0.579</td> <td>    0.389</td> <td> 0.697</td> <td>   -0.910</td> <td>    1.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg</th>  <td>    0.7787</td> <td>    0.404</td> <td>    1.925</td> <td> 0.054</td> <td>   -0.014</td> <td>    1.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalach</th>  <td>    0.0167</td> <td>    0.012</td> <td>    1.450</td> <td> 0.147</td> <td>   -0.006</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exang</th>    <td>   -1.4455</td> <td>    0.468</td> <td>   -3.091</td> <td> 0.002</td> <td>   -2.362</td> <td>   -0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>  <td>   -0.6387</td> <td>    0.241</td> <td>   -2.651</td> <td> 0.008</td> <td>   -1.111</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>    <td>    0.4844</td> <td>    0.397</td> <td>    1.219</td> <td> 0.223</td> <td>   -0.295</td> <td>    1.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>       <td>   -0.7140</td> <td>    0.207</td> <td>   -3.441</td> <td> 0.001</td> <td>   -1.121</td> <td>   -0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>     <td>   -0.9965</td> <td>    0.327</td> <td>   -3.052</td> <td> 0.002</td> <td>   -1.637</td> <td>   -0.356</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                  242\n",
       "Model:                          Logit   Df Residuals:                      228\n",
       "Method:                           MLE   Df Model:                           13\n",
       "Date:                Sat, 07 May 2022   Pseudo R-squ.:                  0.4963\n",
       "Time:                        23:05:28   Log-Likelihood:                -83.993\n",
       "converged:                       True   LL-Null:                       -166.74\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.518e-28\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.5270      3.012      1.503      0.133      -1.377      10.431\n",
       "age           -0.0069      0.027     -0.255      0.799      -0.060       0.046\n",
       "sex           -1.4691      0.523     -2.807      0.005      -2.495      -0.443\n",
       "cp             0.9343      0.213      4.379      0.000       0.516       1.352\n",
       "trestbps      -0.0217      0.012     -1.880      0.060      -0.044       0.001\n",
       "chol          -0.0032      0.004     -0.742      0.458      -0.012       0.005\n",
       "fbs            0.2254      0.579      0.389      0.697      -0.910       1.361\n",
       "restecg        0.7787      0.404      1.925      0.054      -0.014       1.571\n",
       "thalach        0.0167      0.012      1.450      0.147      -0.006       0.039\n",
       "exang         -1.4455      0.468     -3.091      0.002      -2.362      -0.529\n",
       "oldpeak       -0.6387      0.241     -2.651      0.008      -1.111      -0.167\n",
       "slope          0.4844      0.397      1.219      0.223      -0.295       1.263\n",
       "ca            -0.7140      0.207     -3.441      0.001      -1.121      -0.307\n",
       "thal          -0.9965      0.327     -3.052      0.002      -1.637      -0.356\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     מעל - הדיוק כפי שנמצא עבור כלל הפיצ'רים וטבלה המרכזת את הנתונים הסטטיסטיים בהתאמה של הפונקציה. נשים לב שלכל פיצ'ר הפונקציה מצאה גם את הPV שלו. אמנם ניתן להמשיך להשתמש בדיוק, אבל בסעיף זה אני בוחר להשתמש בPV על מנת למיין פיצ'רים.\n",
    "    <br />\n",
    "    בסעיף זה ביקשו מאיתנו להתחיל עם כלל הפיצ'רים ולהוריד אחד-אחד עד שנישאר עם סט של ארבעה - שיטה שנקראת Backward elimination (ובמקומות מסוימים Sequential Backward Selection). \n",
    "    <br />\n",
    "    בשיטה זו נוריד כל פעם את הפיצ'ר עם הPV הכי גבוה ונאמן. נמצא שוב את הפיצ'ר עם ה PV הכי גבוה ונוריד אותו וחוזר חלילה.\n",
    "    <br />\n",
    "    למטה הקוד הרלוונטי עטוף בפונקציה על מנת להדגים נקודה כלשהי בהמשך.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(n, df_train):\n",
    "    selected_features = df_train.drop('target',axis='columns').columns.to_list()\n",
    "\n",
    "    while len(selected_features) > n:\n",
    "        lr = sm.Logit(df_train['target'], sm.add_constant(df_train[selected_features]))\n",
    "        results = lr.fit(disp=0)\n",
    "\n",
    "        worst_pvalue_feature = results.pvalues.sort_values(ascending=False).index[0]\n",
    "\n",
    "        if worst_pvalue_feature == 'const':\n",
    "            worst_pvalue_feature = results.pvalues.sort_values(ascending=False).index[1]\n",
    "\n",
    "\n",
    "        selected_features.remove(worst_pvalue_feature)\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp', 'exang', 'oldpeak', 'ca']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = backward_elimination(4, df_train)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416771\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = sm.Logit(df_train['target'], sm.add_constant(df_train[selected_features]))\n",
    "\n",
    "results = lr.fit()\n",
    "\n",
    "predictions = results.predict(sm.add_constant(df_val[selected_features]))>=0.5\n",
    "accuracy_score(df_val[\"target\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387096774193549"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = results.predict(sm.add_constant(df_test[selected_features]))>=0.5\n",
    "accuracy_score(df_test[\"target\"], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     למעשה, ניתן לראות מה יתרחש עבור כל בחירה של מספר פיצ'רים כלשהו. על מנת לעשות זאת נבחר כל פעם מספר בין 1 ל13 (מספר העמודות בדאטא), נמצא את הפיצ'רים על ידי הפונקציה שכתבנו, נאמן על קבוצת האימון ונבדוק את התוצאות על קבוצת הוולידציה.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultsDF = []\n",
    "\n",
    "for n in range(1,len(df_train.drop('target',axis='columns').columns.to_list())):\n",
    "    selected_features = backward_elimination(n, df_train)\n",
    "\n",
    "    lr = sm.Logit(df_train['target'], sm.add_constant(df_train[selected_features]))\n",
    "    results = lr.fit(disp=0)\n",
    "\n",
    "    predictions = results.predict(sm.add_constant(df_val[selected_features]))>=0.5\n",
    "    \n",
    "    resultsDF.append(pd.DataFrame(\n",
    "        {'n_features': n, 'Accuracy': accuracy_score(df_val[\"target\"], predictions)},index=[0]))\n",
    "resultsDF = pd.concat(resultsDF)\n",
    "p = resultsDF.plot.scatter(x='n_features', y='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "    נשים לב ששתי השיטות האלה ממומשות בsklearn תחת <code>SequentialFeatureSelector</code> יחד עם קרוס ואלידציה <br />ֿ\n",
    "    הנה הצצה לאיך ניתן להשתמש בהן:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward Index(['cp', 'thalach', 'ca', 'thal'], dtype='object')\n",
      "backward Index(['cp', 'oldpeak', 'ca', 'thal'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "sfs = SequentialFeatureSelector(LogisticRegression(max_iter = 1e3), n_features_to_select=4)\n",
    "sfs.fit(df_train.drop('target', axis='columns'), df_train['target'])\n",
    "\n",
    "print(\"forward\", df_train.drop('target', axis='columns').columns[sfs.get_support()])\n",
    "\n",
    "sfs = SequentialFeatureSelector(LogisticRegression(max_iter = 1e3), n_features_to_select=4, direction='backward')\n",
    "sfs.fit(df_train.drop('target', axis='columns'), df_train['target'])\n",
    "\n",
    "print(\"backward\", df_train.drop('target', axis='columns').columns[sfs.get_support()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "    באופן כללי שני הכיוונים לרוב לא יחזירו את אותה התוצאה. <br />\n",
    "    נשים לב שגם לא קיבלנו את אותה התשובה כמו המימוש שלנו בשני המקרים. אחת הסיבות היא שלא השתמשנו בקורס ולידציה בבחירת הפיצ׳ר הראשוני וכמו כן גם בבחירת הפיצ׳רים הבאים. סיבה נוספת היא שהשתמשנו בתהליך הbackward בPV בשביל אלימינציה בעוד שבמימוש של sklearn אנחנו משתמשים במדד הaccuracy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     לשתי השיטות שראינו עד כה יש מספר חסרונות. נמנה שתיים מהן. הראשונה היא שבחירה כזו של פיצ'רים לא לוקחת בחשבון את כל הצירופים האפשריים - בכל שלב בוחרים פיצ'ר אחד ומוסיפים אותו לקבוצה, אבל לא לוקחים בחשבון צירוף של אותו פיצ'ר עם קבוצות אחרות. החיסרון השני הוא שבתהליך אנחנו מאמנים הרבה מודלים לכן השיטות מותאמות למודלים פשוטים ולמעט דאטא.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "     ו. מצאו אילו פיצ'רים כדאי להוריד כך שנישאר עם סט אופטימלי. ביחנו את עצמכם הן על קבוצת הוולידציה והן על קבוצת המבחן.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "     ניתן להתמודד עם החיסרון הראשון והוא על ידי שימוש בפונקציה רקורסיבית. פונקציה רקורסיבית עוברת על כל הקבוצות האפשריות של פיצ'רים ובוחרת מתוכם את זו הנותנת את הביצועים האופטימליים. נשים לב שבכך שפתרנו את הבעיה הראשונה - החמרנו את השנייה.\n",
    "    <br />\n",
    "    אמנם ניתן לממש זאת בעצמינו, במקרה זה מומלץ מאוד להשתמש במימוש מוכן. זאת משום שאנחנו נשתמש בפונקציה על מעט לאמן מספר גדול של מודלים, וללא מימוש אופטימלי זמן הריצה יהיה בלתי סביר. הפונקציה RFECV של Scikir-Learn מבצעת את הפעולה עבורינו:\n",
    "    <br /> Recursive Feature Elimination with Cross Validation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellemiller/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1e3)\n",
    "rfe = RFECV(model, min_features_to_select=1)\n",
    "\n",
    "train_val = pd.concat([df_train, df_val])\n",
    "\n",
    "rfe.fit(train_val.drop('target',axis='columns'), train_val['target'])\n",
    "selected_columns = train_val.drop('target',axis='columns').columns[\n",
    "    rfe.support_\n",
    "]\n",
    "\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_val[selected_columns], train_val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709677419354839"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(df_test[selected_columns])\n",
    "accuracy_score(df_test[\"target\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross validation score (accuracy)')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\n",
    "    range(1, len(rfe.grid_scores_) + 1),\n",
    "    rfe.grid_scores_,\n",
    ")\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (accuracy)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "     ואכן קיבלנו סט של פיצ'רים עם דיוק מסוים בקבוצת וולידציה כלשהי (חיצונית לתהליך הקרוס-וולידציה).\n",
    "    <br /><br />\n",
    "    כעת מבין כל השיטות שלהלן נשאר לבחור סט כלשהו של פיצ'רים. איך? דבר אחד שלא עושים הוא לבחור סט פיצ'רים על בסיס הביצועים בקבוצת המבחן. קבוצת המבחן משמשת מדד לביצועים בעולם האמיתי. בעולם של למידת מכונה - המכונה לומדת מקבוצת האימון והאלגוריתמאי לומד מקבוצת הוולידציה אילו מטה-פרמטרים לבחור. האלגוריתם לאחר מכן יוצא לעולם ונבחן. בחירת סט של פיצ'רים על בסיס קבוצת המבחן משמעה אוברפיט - משמעה שהמטה פרמטרים של המודל נבחרו תוך שימוש בקבוצת המבחן ונעשתה למידה (של הגורם האנושי) באותה קבוצה.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
