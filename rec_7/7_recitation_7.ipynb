{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yq-DYne8PyJF"
   },
   "source": [
    "# <div dir=rtl> תרגול שביעי - SVM, Validation, Cross-Validation </div>\n",
    "<div dir=rtl>\n",
    "    בתרגול זה נכיר כלי נוסף בעולם הלמידה המפוקחת ונלמד איך לבחון את עצמינו יותר טוב.\n",
    "</div>\n",
    "\n",
    "## <div dir=rtl>שאלה 1</div>\n",
    "\n",
    "<div dir=rtl>\n",
    "    בשנת 2008 פרסם הNIH האמריקאי מידע על אודות 4238 תושבי העיר פארמינגהם במדינת מסצ'וסטס. <br />\n",
    "    המידע כלל נתונים על בריאותם של המשתתפים במחקר והאם בתוך עשור המשתתפים זוהו כסובלים ממחלות בכלי הדם הכליליים בלב. המידע זמין בקובץ 6_heart_disease_2.csv. <br />\n",
    "</div>\n",
    "<div dir=rtl style='background-color: #fcf2f2;'> \n",
    "    הערה: הדאטאסט אמיתי וניתן להורדה בצורה חופשייה. הנתונים בו שונו לצורך הדוגמה. <br />\n",
    "</div><br />\n",
    "<div dir=rtl>\n",
    "    א. טענו את הקובץ לאובייקט מסוג DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmUG4jHpPyJH"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NVMMsvdPyJX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('6_heart_disease_2.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-NyiewZPyJl"
   },
   "source": [
    "<div dir=rtl>\n",
    "    ב. בתרגול קודם הכרנו את כלל הפיצ'רים בדאטא סט והתרשמנו כי לחץ הדם הסיסטולי ולחץ הדם הדיאסטולי מהווים מדדים המפרידים במידה מסוימת בין המטופלים החולים והבריאים. <br />\n",
    "    בתרגול הקודם התאמנו מודל לוגיסטי לכל הנתונים יחד וחישבנו את מדד הדיוק <br />\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "\\begin{align}\n",
    "Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}\\\\\n",
    "\\end{align}\n",
    "<br />\n",
    "\n",
    "<div dir=rtl>\n",
    "    ראינו בתרגול הקודם שהפרדה גם בעזרת שני פיצ׳רים לא כל כך אינפורמטיבים (BMI ודופק) עדיין נתנו ציון דיוק גבוה, מעל 0.8. למה זה קורה?<br />\n",
    "    ננסה להבין זאת ע״י דוגמה - נניח שיש לנו דאטה סט שמכיל 1000 תצפיות שמסומנות כ-0 ו10 תצפיות שמסומנת כ-1. <br />\n",
    "    בנוסף נניח שיש לנו מודל קלאסיפיקציה ״מנוון״, כלומר לכל התצפיות המודל נותן את הפרדיקציה 0. מה יהיה ציון הדיוק?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate((np.zeros(1000), np.ones(10)))\n",
    "y_pred = np.zeros(y_true.shape[0])\n",
    "\n",
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "    אבל המודל הזה ממש לא מודל טוב....אם נשים לב במודל הגרוע ביותר אנחנו נקבל שמדד הדיוק שווה ליחס בין כמות התצפיות של הקבוצה הגדולה ביותר לכל הדאטה סט - הTN תמיד יהיה מספר מאוד גדול! כי הדאטה ממש לא מאוזן <br />\n",
    "    נתבונן בעוד שני מדדי דיוק - <code>precision</code> ו - <code>recall</code>\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "\\begin{align}\n",
    "Precision = \\frac{TP}{TP+FP}\\\\\n",
    "    Recall = \\frac{TP}{TP+FN}\\\\\n",
    "\\end{align}\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "    מדד ה- <code>precision</code> מתאר כמה המודל מסווג טוב דוגמאות למחלקה החיובית (1) כלומר כמה תצפיות מתוך כל התצפיות שהכרזנו עליהן כחיוביות אכן חיוביות<br />\n",
    "    מדד ה- <code>recall</code>, ידוע גם כ sensitivity מתאר כמה המודל מצליח לסווג נכונה את המחלקה החיובית מתוך סך כל ההופעות שלה בדאטה. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.precision_score(y_true, y_pred))\n",
    "print(metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "        בדקו האם הדאטה מאוזן או לא \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW9zCN_8PyJn"
   },
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (10, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large',\n",
    "         'axes.grid':True,\n",
    "         'axes.grid.which':'both'\n",
    "         }\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['TenYearCHD'], palette='coolwarm')\n",
    "# shorter but the same as df['TenYearCHD'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yST3UIZRPyJ4"
   },
   "source": [
    "\n",
    "<div dir=rtl>\n",
    "    ג. צרו חלוקה ברשומות כך שבקבוצה אחת יפלו 80% מהדוגמאות, ושאר הדוגמאות בקבוצה השניה. שימו לב שעליכם לחלק את הרשומות כך שהתפלגות המחלקות תישאר זהה בכל קבוצה.\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "<div dir=rtl>\n",
    "    ראשית ננסה להבין מה התפלגות המחלקות בנתונים:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUTRxyIFPyJ5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    df['TenYearCHD'].value_counts(normalize=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byhC82MzPyKD"
   },
   "source": [
    "<div dir=rtl>\n",
    "    קבלנו שרוב הנתונים מגיעים מנבדקים בריאים - יש הטייה חזקה בדאטא לטובת המחלקה הזו. נשים לב שאם נבחר באקראי רשומות לכל קבוצה (אנחנו רוצים שתי קבוצות) החלוקה עלולה להיות כזו שמחלקה אחת תהיה מיוצגת בצורה לא טובה - או בייצוג חסר או בייצוג יתר. אנחנו רוצים לדאוג לכך שגם אחרי החלוקה לשתי קבוצות ההתפלגות תישמר 85-15.\n",
    "    <br />\n",
    "    אמנם ניתן לממש זאת בעצמינו, אבל למזלינו מימוש מוכן ובדוק כבר קיים:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WC-ibG2IPyKE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val = train_test_split(\n",
    "    df[['sysBP','diaBP', 'TenYearCHD']],\n",
    "    train_size=0.8,\n",
    "    stratify=df['TenYearCHD']\n",
    ")\n",
    "pd.DataFrame(x_train['TenYearCHD'].value_counts(normalize=True)),\\\n",
    "pd.DataFrame(x_val['TenYearCHD'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzBbim33PyKM"
   },
   "source": [
    "<div dir=rtl>\n",
    "    נשים לב לפרמטר stratify (מאנגלית: סטרטיפיקציה - יצרת שכבות). הוא מנחה את הפונקציה לחלק את הנתונים לפי הלייבלים הנתונים לו. אכן בהסתכלות על ההתפלגות בכל קבוצה - מקבלים שהתפלגות הלייבלים נשמרה כמו במקור בדיוק גבוה.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "    ד. צרו מודל לינארי לסיווג הנתונים לשתי מחלקות אשר ממקסם את המרחק בין שתי המחלקות והישר המפריד. יש ללמוד מהקבוצה הגדולה (זו שסומנה ב train)\n",
    "</div>\n",
    "<br />\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "    בדיוק לשם כך נוצר ה Support Vector Machine. <br />\n",
    "    מדובר במודל אשר מתאים מפריד לינארי (קו ישר, מישור או מישור במימד גבוה) ואך ורק לינארי. בתהליך האימון המודל מתחשב במרחק בין הישר המפריד לדוגמאות הקרובות ביותר אליו מכל מחלקה (אלה ווקטורי התמך) ומעביר את הישר בניהם.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "    את שתי המחלקות נסמן באופן הבא $y_i \\in \\{-1,1\\}$ והמטרה שלנו היא למצוא ישר או מישור שמפריד בצורה הטובה ביותר את הנקודות של שתי המחלקות. <br />\n",
    "    כלומר, נרצה שהפרדיקציות יהיו בעלות אותו הסימן :\n",
    "</div>\n",
    "\n",
    "\\begin{align}\n",
    "y_i(w^T \\cdot x_i - b) ֿ\\geq 1\\\\\\forall i, 1 \\leq i \\leq n\\\\\n",
    "\\end{align}\n",
    "\n",
    "<br /><br />\n",
    "<div dir=rtl>\n",
    "    הבעיה בדוגמה הזו היא שהדאטה לא תמיד יהיה ניתן להפרדה מושלמת ע״י קו לינארי. בשביל לאפשר יותר גמישות באלגוריתם נסתמך על soft-SVM שמאפשר סטייה מההפרדה הלינארית המושלמת ובעצם ״מעניש״ נקודות שמעבר לקו.<br />\n",
    "    הפונקציה שנשתמש בה במקרה זה נקראת גם <code>hinge loss</code> והיא מקבלת את הערך 0 כאשר הנקודה נמצאת בצד הנכון של הישר, אחרת ערך הפרופורציונאלי למרחק של הנקודה מהישר\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHAToZh8PyKN"
   },
   "source": [
    "\\begin{align}\n",
    "l_i = \\max(0, 1 - y_i(w^T \\cdot x_i - b))\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "   בפועל נרצה למזער את הloss אבל לשמור על שוליים כמה שיותר גדולים\n",
    "</div>\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{w}, \\hat{b} = ||w||^2 + C\\sum{L_{hinge}(y_i, w^T \\cdot x_i - b)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "<br /><br />\n",
    "<div dir=rtl>\n",
    "    הפרמטר C מגדיר את גודל הרגולריזציה והוא עוזר למודל להתכנס במצבים בהם יש \"רעש\" והדגימות לא מופרדות בצורה מושלמת על ידי ישר. הוא מאזן בין ערך ה- <code>loss</code> לבין גודל השוליים: <br />\n",
    "    כאשר C גדול - עדיפות לשוליים קטנים יותר אם זה מוביל לקלאסיפיקציה טובה יותר.<br />\n",
    "    עבור C קטן יותר - יותר משקל לשוליים רחבים ופחות לקלאסיפיקציה לא נכונה.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div dir=rtl>\n",
    "    צרו תרשים פיזור של שני הפיצ׳רים: sysBP, diaBP\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acZL0aE8PyKO"
   },
   "outputs": [],
   "source": [
    "boxp = x_train[['sysBP','diaBP','TenYearCHD']].plot.scatter(\n",
    "    x='diaBP',\n",
    "    y='sysBP',\n",
    "    c='TenYearCHD',\n",
    "    cmap='jet',\n",
    "    sharex=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8k9bwxYPyKU"
   },
   "source": [
    "<div dir=rtl>\n",
    "    כעת נתאים מודל SVM עבור קלסיפיקציה:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmZOwcxGPyKV"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(\n",
    "    x_train[['diaBP','sysBP']], \n",
    "    x_train['TenYearCHD']\n",
    ")\n",
    "\n",
    "\n",
    "boxp = x_train[['sysBP','diaBP','TenYearCHD']].plot.scatter(\n",
    "    x='diaBP',\n",
    "    y='sysBP',\n",
    "    c='TenYearCHD',\n",
    "    cmap='jet',\n",
    "    sharex=False\n",
    ")\n",
    "\n",
    "def decision_boundary_plot(results, min_x, max_x):\n",
    "    # get the separating hyperplane\n",
    "    w = results.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (results.intercept_[0]) / w[1]\n",
    "    plt.plot(xx, yy, c='darkorange', lw=4)\n",
    "\n",
    "\n",
    "\n",
    "decision_boundary_plot(svc, x_train['diaBP'].min(), x_train['diaBP'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same plot but now showing support vectors\n",
    "plt.scatter(x_train['diaBP'], x_train['sysBP'], c=x_train['TenYearCHD'], s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the decision function\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = svc.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.9, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SDqqe5yFPyKc"
   },
   "source": [
    "<div dir=rtl>\n",
    "    ה. בחנו את ביצועי המודל הן על הקבוצת האימון והן על קבוצת הוולידציה.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4l8noNePyKd"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(\n",
    "    x_train['TenYearCHD'],\n",
    "    svc.predict(x_train[['diaBP','sysBP']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiKnDHntPyKl"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(\n",
    "    x_val['TenYearCHD'],\n",
    "    svc.predict(x_val[['diaBP','sysBP']])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGWgiGtNPyKr"
   },
   "source": [
    "<div dir=rtl>\n",
    "    באופן צפוי - קיבלנו ביצועים פחות טובים על קבוצת הוולידציה מאשר על קבוצת האימון (אבל - זה לא חד משמעי). זה יכול לנבוע ממגוון סיבות - רעש בדוגמאות שבחרנו ללמידה, רעש בוולידציה, בחירה לא מוצלחת של נקודות ועוד.\n",
    "    <br />\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "    ו. חיזרו על התהליך.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHr4egT1PyKs"
   },
   "outputs": [],
   "source": [
    "x_train, x_val = train_test_split(\n",
    "    df[['sysBP','diaBP', 'TenYearCHD']],\n",
    "    train_size=0.8,\n",
    "    stratify=df['TenYearCHD']\n",
    ")\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(\n",
    "    x_train[['diaBP','sysBP']], \n",
    "    x_train['TenYearCHD']\n",
    ")\n",
    "\n",
    "metrics.accuracy_score(\n",
    "    x_val['TenYearCHD'],\n",
    "    svc.predict(x_val[['diaBP','sysBP']])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMF0qM7HPyK0"
   },
   "source": [
    "<div dir=rtl>\n",
    "    למעשה אנחנו רואים שבחלוקות חוזרות ונשנות של הדאטא מקבלים נתונים שונים. נשאלות כעת השאלות: איך נבחר את הפרמטרים האופטימליים של המודל בצורה אמינה? על אילו נתונים נדווח?\n",
    "</div>\n",
    "<br />\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "    ז. חלקו את הנתונים לחמש חלוקות 80-20 ייחודיות וזרות אחת לשניה ואמנו מודל על כל חלוקה. ביחרו על בסיס זה את חוזק הרגולריזציה.\n",
    "</div>\n",
    "<br />\n",
    "<div dir=rtl>\n",
    "    כעת נכיר את מושג הקרוס-וולידציה. בשיטה זה משתמשים בכל הדאטא לאימון (למעט קבוצת מבחן בה לא נוגעים עד השלב האחרון). בכל סבב מאמנים מודל אחר ובודקים את התוצאות שלו.\n",
    "    <br />\n",
    "    קרוס וולידציה היא צורה אמינה יותר לדיווח על תוצאות משום שמבטלת את החלוקה כגורם המשפיע על המודל.\n",
    "    <br />\n",
    "    אמנם לא מסובך לממש זאת בעצמינו, אבל למזלינו קיים מימוש מוכן ובדוק.\n",
    "</div>\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teIHCrR7PyK1"
   },
   "source": [
    "![](7_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKUWbFYgPyK2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "scores = cross_val_score(\n",
    "    svc,\n",
    "    df[['sysBP', 'diaBP']],\n",
    "    df['TenYearCHD'],\n",
    "    cv=skf\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoRzK6IKPyK8"
   },
   "source": [
    "<div dir=rtl>\n",
    "    נשים לב למעלה שקיבלנו 5 מספרים - חמישה ערכי דיוק. עוד נשים לב שהמודל בו אנחנו משתמשים, svc, הוא מודל שהחבילה \"יודעת\" לעבוד איתו, לכן התהליך כולו אוטומטי.\n",
    "    <br />\n",
    "    כעת, תוך שימוש בשיטה הזו נבחר פרמטר C מתאים:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BB5GnWyaPyK-"
   },
   "outputs": [],
   "source": [
    "regularization_strength = [1e-5, 1e-4, 1e-3 ,0.01, 0.1, 1]\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    [],\n",
    "    columns=regularization_strength\n",
    ")\n",
    "\n",
    "for strength in regularization_strength:\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    svc = SVC(kernel='linear', C=strength)\n",
    "    scores = cross_val_score(\n",
    "        svc,\n",
    "        df[['sysBP', 'diaBP']],\n",
    "        df['TenYearCHD'],\n",
    "        cv=skf\n",
    "    )\n",
    "    \n",
    "    results.loc[:,strength] = scores\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUrIPs4ePyLF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pointplot(\n",
    "    data=results,\n",
    "    ci='sd'\n",
    ")\n",
    "\n",
    "xl = plt.xlabel('Regularization Parameter')\n",
    "yl = plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ou2xP0rPyLL"
   },
   "source": [
    "<div dir=rtl>\n",
    "    בתרשים למעלה קיבלנו את הממוצע וסטיית התקן של חמש ריצות שונות של המודל על חמש חלוקות שונות של הדאטא. רווח הסמך שבחרנו לבקש מהמודל להציג הוא הסטיית תקן. כעת נוכל לבחור פרמטר בצורה מושכלת ומוצדקת.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_recitation_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
